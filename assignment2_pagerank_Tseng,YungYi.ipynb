{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharon-Tseng/ISOM3770_Big_Data/blob/main/assignment2_pagerank_Tseng%2CYungYi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x36kyK_ssIhz"
      },
      "source": [
        "## ISOM 3370 Assignment 2  \n",
        "\n",
        "PageRank is an algorithm used by Google to rank web pages in the search engine results. PageRank is an iterative algorithm which is a perfect fit for Spark. In this question, you will implement PageRank algorithm with PySpark by completing the following codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3c82UlPsGhv"
      },
      "outputs": [],
      "source": [
        "# download Java 11\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# download Spark 3.4.0 + Hadoop 3\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.0-bin-hadoop3.tgz\n",
        "\n",
        "# install findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "# setup enviornment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "conf = SparkConf().setAppName(\"TestApp\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GejG0GIWsPGA"
      },
      "source": [
        "First, we create the sample network list object in Spark RDD, as below.\n",
        "\n",
        "This object has format: **source_page target_page**. Below is the content of the object.\n",
        "\n",
        "\n",
        "page1 page3\n",
        "\n",
        "page2 page1\n",
        "\n",
        "page4 page1\n",
        "\n",
        "page3 page1\n",
        "\n",
        "page4 page2\n",
        "\n",
        "page3 page4\n",
        "\n",
        "Run the following cells, and complete the cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6AZ5rSts4IS"
      },
      "outputs": [],
      "source": [
        "# load the file and persist the RDD in memory.\n",
        "rdd = sc.parallelize(['page1 page3', 'page2 page1', 'page4 page1', 'page3 page1', 'page4 page2', 'page3 page4']).persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBIMw-GTeeYl",
        "outputId": "d70f1229-f5f9-4b70-9c55-4625a845a5b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['page1 page3',\n",
              " 'page2 page1',\n",
              " 'page4 page1',\n",
              " 'page3 page1',\n",
              " 'page4 page2',\n",
              " 'page3 page4']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AwXpRUQs7vA"
      },
      "outputs": [],
      "source": [
        "# this is how we compute contribute score for each link.\n",
        "# for example, if a page's rank is 1.0 and it has 2 outgoing links, each links will have contribution 0.5.\n",
        "# (neighbors=[page1, page2], rank=1.0)  => ([(page1, 0.5), (page2,0.5)])\n",
        "def computeContribs(neighbors, rank):\n",
        "    for neighbor in neighbors:\n",
        "        yield (neighbor, rank/len(neighbors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpUrVNMws9Au",
        "outputId": "7c42a5ce-3977-4c0d-e31f-a1c5d5527c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page2 ['page1']\n",
            "page1 ['page3']\n",
            "page4 ['page1', 'page2']\n",
            "page3 ['page1', 'page4']\n"
          ]
        }
      ],
      "source": [
        "# TO COMPLETE: for each page, output its outgoing neighbors in a list.\n",
        "# For example: page3 has two outgoing links to page 1 and page4, the output will be (page3, [page1, page4])\n",
        "# The content of linksRDD is:\n",
        "# page4 [u'page1', u'page2']\n",
        "# page2 [u'page1']\n",
        "# page3 [u'page1', u'page4']\n",
        "# page1 [u'page3']\n",
        "\n",
        "result = rdd.map(lambda line: line.split())\\\n",
        "        .map(lambda node: (node[0], node[1]))\\\n",
        "        .groupByKey()\\\n",
        "        .mapValues(lambda dest: list(dest)).persist()\n",
        "\n",
        "\n",
        "for (source, dest) in result.collect():\n",
        "  print(f'{source} {dest}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK6buXDys-hW",
        "outputId": "2645db42-df5d-49bb-a398-879b1b52a1ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('page4', 1.0), ('page2', 1.0), ('page3', 1.0), ('page1', 1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# TO COMPLETE: for each page, initialize its pagerank score to be 1.0\n",
        "# The content of ranksRDD is:\n",
        "# [(u'page4', 1.0), (u'page2', 1.0), (u'page3', 1.0), (u'page1', 1.0)]\n",
        "\n",
        "ranksRDD = sc.parallelize([(u'page4', 1.0), (u'page2', 1.0), (u'page3', 1.0), (u'page1', 1.0)])\n",
        "ranksRDD.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ2nDNFqtBz1"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE: PageRank is an iterative algorithm.\n",
        "# For each iteration, each page's pagerank score will be updated.\n",
        "# Refer to lecture slides for method details.\n",
        "unique_pages = ranksRDD.keys().collect()\n",
        "\n",
        "for iteration in range(10):\n",
        "    # calculate the contribution of each page's outgoing link\n",
        "    contribution = result.join(ranksRDD).flatMap(\n",
        "        lambda x: computeContribs(x[1][0], x[1][1])\n",
        "    )\n",
        "    # update each page's page rank by summing up all incoming link's contribution\n",
        "    new_pr = contribution.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "    ranksRDD = sc.parallelize(unique_pages)\\\n",
        "            .map(lambda page: (page, None))\\\n",
        "            .leftOuterJoin(new_pr)\\\n",
        "            .mapValues(lambda x: x[1] if x[1] is not None else 0.0)\\\n",
        "            .persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68i2voJynpjY",
        "outputId": "b9e52fd3-ffd7-422c-9913-0f7444ca76d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page2:0.375\n",
            "page3:1.484375\n",
            "page1:1.4296875\n",
            "page4:0.7109375\n"
          ]
        }
      ],
      "source": [
        "# Return the final page rank score of each page. The results is\n",
        "# [(u'page4', 0.7109375), (u'page2', 0.375), (u'page3', 1.484375), (u'page1', 1.4296875)]\n",
        "\n",
        "for (page, pr) in ranksRDD.collect():\n",
        "  print(f'{page}:{pr}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}